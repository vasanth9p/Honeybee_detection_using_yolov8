{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.0.196\n",
        "!pip install roboflow --quiet"
      ],
      "metadata": {
        "id": "8qHxIdYu13p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "9M3DEVra2JE1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Dataset credits:- Roboflow***\n",
        "\n",
        "As i haven't prepared any dataset, so iam using honey-bee dataset from Roboflow.\n",
        "\n",
        "\n",
        "If you want to train yolo v8 on your custom data just skip the below cell. instead of runnig below cell you can create a folder structure in this format.\n",
        "\n",
        "# ***Folder structure***\n",
        "\n",
        "*   honey_bee_dataset --main folder\n",
        "*   ---***train***\n",
        "*   --------images\n",
        "*   --------labels\n",
        "*   ---***test***\n",
        "*   --------images\n",
        "*   --------labels\n",
        "*   ---***valid***\n",
        "*   --------images\n",
        "*   --------labels\n",
        "*   ---***data.yaml***\n",
        "\n",
        "In train, test and valid folder will contain two folders images and labels. In both folders respective images and labels or annotated files has to be there.\n",
        "\n",
        "For example in images folder has honey_bee1.jpg file, in labels folder honey_bee1.txt labels file/annotated file should be there.\n",
        "\n",
        "***Example honey_bee1.txt***\n",
        "\n",
        "0 0.3875 0.5857 0.05745 0.0702\n",
        "\n",
        "2 0.910625 0.6073 0.048499999999999995 0.046733333333333335\n",
        "\n",
        "0 0.807825 0.6534333333333333 0.05125 0.048266666666666666\n",
        "\n",
        "1 0.10980000000000001 0.6565333333333334 0.0587 0.05443333333333333\n",
        "\n",
        "Here 0,1,2 are class names and following values are bounding boxes for those class.\n",
        "\n",
        "\n",
        "\n",
        "data.yaml is the import file for taraing the yolov8 model. In this file we mention the paths for train and test folders. and classes used for the training.\n",
        "\n",
        "***Example data.yml file info:-***\n",
        "\n",
        "names:    #classes used in the annotation process\n",
        "- bee\n",
        "- drone\n",
        "- pollenbee\n",
        "- queen\n",
        "\n",
        "nc: 4     #no of classes\n",
        "\n",
        "test: test/images      #path to the train, test and valid folders\n",
        "\n",
        "train: train/images\n",
        "\n",
        "val: valid/images\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pLqK0chV4u7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Your roboflow api key\")    # replace with your key\n",
        "project = rf.workspace(\"matt-nudi\").project(\"honey-bee-detection-model-zgjnb\")\n",
        "dataset = project.version(4).download(\"yolov8\")\n"
      ],
      "metadata": {
        "id": "dRisgVW01228"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "# model = YOLO('yolov8n.yaml')  # build a new model from YAML you can use this line to train the model from scratch\n",
        "model = YOLO('yolov8s.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/Honey-Bee-Detection-Model-4/data.yaml', epochs=3, imgsz=640)"
      ],
      "metadata": {
        "id": "ykJjJvRv25vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To validate the model\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPmoi5h3CBPl",
        "outputId": "beabce1e-e854-4eaf-9f88-2514fdd146a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11127132 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Honey-Bee-Detection-Model-4/valid/labels.cache... 176 images, 20 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:10<00:00,  1.01it/s]\n",
            "                   all        176       1809      0.505       0.43      0.392      0.227\n",
            "                   bee        176       1669      0.772      0.727      0.768      0.447\n",
            "                 drone        176         31      0.758      0.161      0.319      0.185\n",
            "             pollenbee        176        106      0.425        0.5      0.433       0.26\n",
            "                 queen        176          3     0.0672      0.333     0.0477     0.0164\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.44663,     0.18475,     0.25998,    0.016406])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to run predictions on new image\n",
        "# Load a model\n",
        "\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "# Predict with the model\n",
        "results = model('/content/Honey-Bee-Detection-Model-4/valid/images/1_mp4-1_jpg.rf.c6c4db5bcad5698eef18d8ff37ae4f42.jpg',save = True)  # predict on an image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJeLY44pCmXi",
        "outputId": "57dec185-4b12-41ac-dbb0-d4472c61d1c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/Honey-Bee-Detection-Model-4/valid/images/1_mp4-1_jpg.rf.c6c4db5bcad5698eef18d8ff37ae4f42.jpg: 512x864 1 bee, 17.6ms\n",
            "Speed: 4.9ms preprocess, 17.6ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 864)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}